{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m8-94USCEkXj"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import models\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tqdm import tqdm\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") #use GPU if possible\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "data_dir = '/content/drive/MyDrive/BME450Final1'\n",
        "\n",
        "#Preprocessing Training Data\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.Grayscale(), #convert images to grayscale\n",
        "    transforms.RandomHorizontalFlip(), #horizontally flip images at random\n",
        "    transforms.RandomRotation(15), #rotate images up to 15 degrees at random\n",
        "    transforms.Resize((160, 160)), #resize all images to 160 by 160\n",
        "    transforms.ToTensor(), #convert to tensor\n",
        "    transforms.Normalize([0.5], [0.5]) #normalize\n",
        "])\n",
        "\n",
        "#Preprocessing Validation Data\n",
        "transform_val = transforms.Compose([\n",
        "    transforms.Grayscale(), #convert images to grayscale\n",
        "    transforms.Resize((160, 160)), #resize all images to 160 by 160\n",
        "    transforms.ToTensor(), # convert to tensor\n",
        "    transforms.Normalize([0.5], [0.5]) #normalize\n",
        "])\n",
        "\n",
        "#Loading the data\n",
        "train_dataset = ImageFolder(root=os.path.join(data_dir, 'train'), transform=transform_train)\n",
        "val_dataset = ImageFolder(root=os.path.join(data_dir, 'val'), transform=transform_val)\n",
        "\n",
        "#Creating DataLoaders for the data\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "class_names = train_dataset.classes\n",
        "num_classes = len(class_names)\n",
        "print(\"Classes:\", class_names)\n"
      ],
      "metadata": {
        "id": "a-ChKAlpElP6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#MobileNetV2 CNN\n",
        "model = models.mobilenet_v2(pretrained=True) #upload mobilenetv2\n",
        "model.features[0][0] = nn.Conv2d(1, 32, kernel_size=3, stride=2, padding=1, bias=False) #changing 1st conv. layer to accept 1 channel grayscale input\n",
        "model.classifier = nn.Sequential(\n",
        "    nn.Dropout(0.3), #dropout rate with 30% probability, change dropout rate HERE\n",
        "    nn.Linear(model.last_channel, num_classes) #final layer matching classes from data for output\n",
        ")\n",
        "model = model.to(device)\n"
      ],
      "metadata": {
        "id": "nieeQLuwElbn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training function\n",
        "def train_epoch(model, loader, optimizer, loss_fun):\n",
        "    model.train()\n",
        "    running_loss, correct, total = 0.0, 0, 0 #initializing variables\n",
        "    for images, labels in tqdm(loader):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad() #clearing past gradients\n",
        "        outputs = model(images) #forward pass\n",
        "        loss = loss_func(outputs, labels) #calculating loss (predictions and truth)\n",
        "        loss.backward() #backward pass\n",
        "        optimizer.step() #updating weights\n",
        "        running_loss += loss.item() #summing loss\n",
        "        _, preds = torch.max(outputs, 1) #predicting the label\n",
        "        correct += (preds == labels).sum().item() #number of correct predictions\n",
        "        total += labels.size(0)\n",
        "    return running_loss / len(loader), correct / total #returning avg loss and accuracy\n",
        "\n",
        "#Validation Function\n",
        "def eval_epoch(model, loader, loss_func):\n",
        "    model.eval()\n",
        "    running_loss, correct, total = 0.0, 0, 0 #intialize varibles\n",
        "    all_preds, all_labels = [], []\n",
        "    with torch.no_grad(): #disable gradient\n",
        "        for images, labels in loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images) #forward pass\n",
        "            loss = loss_func(outputs, labels) #calculate loss\n",
        "            running_loss += loss.item() #summing loss\n",
        "            _, preds = torch.max(outputs, 1) #predicted class labels\n",
        "            correct += (preds == labels).sum().item() #number of correct predictions\n",
        "            total += labels.size(0)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "    return running_loss / len(loader), correct / total, all_preds, all_labels #return avg loss, accuracy, lists of predictions and labels\n"
      ],
      "metadata": {
        "id": "ggw-GF7ZEleB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 20 #epoch constant\n",
        "loss_func = nn.CrossEntropyLoss() #using cross entropy loss function\n",
        "optimizer = optim.Adam(model.parameters(), lr=.01, weight_decay=1e-4) #CHANGE LR HERE\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS) #learning rate scheduler\n",
        "\n",
        "#Initializing variables for early stopping mechanism\n",
        "best_val_acc = 0\n",
        "patience = 5\n",
        "patience_counter = 0\n",
        "\n",
        "train_accs, val_accs = [], []\n",
        "train_losses, val_losses = [], []\n",
        "\n",
        "#Training Loop\n",
        "for epoch in range(EPOCHS):\n",
        "    print(f\"Epoch {epoch+1}/{EPOCHS}\")\n",
        "    train_loss, train_acc = train_epoch(model, train_loader, optimizer, loss_func)\n",
        "    val_loss, val_acc, _, _ = eval_epoch(model, val_loader, loss_func)\n",
        "    scheduler.step()\n",
        "\n",
        "    train_accs.append(train_acc)\n",
        "    val_accs.append(val_acc)\n",
        "    train_losses.append(train_loss)\n",
        "    val_losses.append(val_loss)\n",
        "\n",
        "    print(f\"Train Loss: {train_loss:.4f}, Accuracy: {train_acc:.4f}\")\n",
        "    print(f\"Val   Loss: {val_loss:.4f}, Accuracy: {val_acc:.4f}\")\n",
        "\n",
        "#Save output if val accuracy has improved\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        patience_counter = 0\n",
        "        torch.save(model.state_dict(), \"best_model.pth\")\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        if patience_counter >= patience:\n",
        "            print(\"Early stopping triggered.\") #training stopped early once count reaches 5\n",
        "            break\n"
      ],
      "metadata": {
        "id": "FZDUZD1BEqUq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting Loss and Accuracy Curves for Train and Val\n",
        "plt.figure\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(train_losses, label='Train Loss')\n",
        "plt.plot(val_losses, label='Val Loss')\n",
        "plt.legend()\n",
        "plt.title('Loss Curve')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(train_accs, label='Train Acc')\n",
        "plt.plot(val_accs, label='Val Acc')\n",
        "plt.legend()\n",
        "plt.title('Accuracy Curve')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "N4t_kWP4EqWx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load(\"best_model.pth\")) #load best model weights\n",
        "_, _, preds, labels = eval_epoch(model, val_loader, loss_func) #evaluate to get predicted and true labels\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(labels, preds, target_names=class_names))\n",
        "\n",
        "#Computing and plotting confusion matrix\n",
        "cm = confusion_matrix(labels, preds)\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.colorbar()\n",
        "plt.xticks(np.arange(num_classes), class_names, rotation=45)\n",
        "plt.yticks(np.arange(num_classes), class_names)\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "9O5dPFn7EvvD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}